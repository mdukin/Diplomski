Ako pretpostavimo da je 
ğ‘Œ
=
1
Y=1 i da je ulaz 
ğ‘¥
=
1
x=1, moÅ¾emo specifiÄno izraÄunati gradijente za zadani primjer. Prvo Ä‡emo zapisati konkretne izraze za svaku varijablu, a zatim izraÄunati gradijente.

Model
Model je:
ğ‘ 
1
=
ğ‘¤
1
â‹…
ğ‘¥
+
ğ‘
1
s 
1
â€‹
 =w 
1
â€‹
 â‹…x+b 
1
â€‹
 
â„
1
=
ReLU
(
ğ‘ 
1
)
h 
1
â€‹
 =ReLU(s 
1
â€‹
 )
ğ‘ 
2
=
ğ‘¤
2
â‹…
â„
1
+
ğ‘
2
s 
2
â€‹
 =w 
2
â€‹
 â‹…h 
1
â€‹
 +b 
2
â€‹
 
ğ‘ 
=
[
ğ‘ 
1
,
ğ‘ 
2
]
s=[s 
1
â€‹
 ,s 
2
â€‹
 ]
ğ‘¦
=
softmax
(
ğ‘ 
)
y=softmax(s)

Funkcija gubitka
Koristimo unakrsnu entropiju kao funkciju gubitka:
ğ¿
=
âˆ’
log
â¡
(
ğ‘¦
1
)
L=âˆ’log(y 
1
â€‹
 )
jer je 
ğ‘Œ
=
1
Y=1.

IzraÄunavanje korak po korak
IzraÄunavanje 
ğ‘ 
1
s 
1
â€‹
  i 
â„
1
h 
1
â€‹
 :
ğ‘ 
1
=
ğ‘¤
1
â‹…
ğ‘¥
+
ğ‘
1
=
ğ‘¤
1
â‹…
1
+
ğ‘
1
=
ğ‘¤
1
+
ğ‘
1
s 
1
â€‹
 =w 
1
â€‹
 â‹…x+b 
1
â€‹
 =w 
1
â€‹
 â‹…1+b 
1
â€‹
 =w 
1
â€‹
 +b 
1
â€‹
 
â„
1
=
ReLU
(
ğ‘ 
1
)
=
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
h 
1
â€‹
 =ReLU(s 
1
â€‹
 )=ReLU(w 
1
â€‹
 +b 
1
â€‹
 )

IzraÄunavanje 
ğ‘ 
2
s 
2
â€‹
 :
ğ‘ 
2
=
ğ‘¤
2
â‹…
â„
1
+
ğ‘
2
=
ğ‘¤
2
â‹…
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
+
ğ‘
2
s 
2
â€‹
 =w 
2
â€‹
 â‹…h 
1
â€‹
 +b 
2
â€‹
 =w 
2
â€‹
 â‹…ReLU(w 
1
â€‹
 +b 
1
â€‹
 )+b 
2
â€‹
 

Konkatenacija 
ğ‘ 
1
s 
1
â€‹
  i 
ğ‘ 
2
s 
2
â€‹
  u 
ğ‘ 
s:
ğ‘ 
=
[
ğ‘ 
1
,
ğ‘ 
2
]
s=[s 
1
â€‹
 ,s 
2
â€‹
 ]

IzraÄunavanje softmaxa 
ğ‘¦
y:
ğ‘¦
ğ‘–
=
ğ‘’
ğ‘ 
ğ‘–
ğ‘’
ğ‘ 
1
+
ğ‘’
ğ‘ 
2
y 
i
â€‹
 = 
e 
s 
1
â€‹
 
 +e 
s 
2
â€‹
 
 
e 
s 
i
â€‹
 
 
â€‹
 

Gradijent gubitka u odnosu na 
ğ‘ 
s:
âˆ‚
ğ¿
âˆ‚
ğ‘ 
ğ‘–
=
ğ‘¦
ğ‘–
âˆ’
ğ‘¡
ğ‘–
âˆ‚s 
i
â€‹
 
âˆ‚L
â€‹
 =y 
i
â€‹
 âˆ’t 
i
â€‹
 
Gdje je 
ğ‘¡
=
[
1
,
0
]
t=[1,0] jer je 
ğ‘Œ
=
1
Y=1.

IzraÄunavanje gradijenata
Prvo izraÄunajmo vrijednosti 
ğ‘ 
1
s 
1
â€‹
  i 
ğ‘ 
2
s 
2
â€‹
  konkretno:

IzraÄunavanje 
ğ‘ 
1
s 
1
â€‹
  i 
â„
1
h 
1
â€‹
 :
ğ‘ 
1
=
ğ‘¤
1
+
ğ‘
1
s 
1
â€‹
 =w 
1
â€‹
 +b 
1
â€‹
 
â„
1
=
ReLU
(
ğ‘ 
1
)
=
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
h 
1
â€‹
 =ReLU(s 
1
â€‹
 )=ReLU(w 
1
â€‹
 +b 
1
â€‹
 )

IzraÄunavanje 
ğ‘ 
2
s 
2
â€‹
 :
ğ‘ 
2
=
ğ‘¤
2
â‹…
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
+
ğ‘
2
s 
2
â€‹
 =w 
2
â€‹
 â‹…ReLU(w 
1
â€‹
 +b 
1
â€‹
 )+b 
2
â€‹
 

IzraÄunavanje softmaxa 
ğ‘¦
y:
ğ‘¦
1
=
ğ‘’
ğ‘ 
1
ğ‘’
ğ‘ 
1
+
ğ‘’
ğ‘ 
2
y 
1
â€‹
 = 
e 
s 
1
â€‹
 
 +e 
s 
2
â€‹
 
 
e 
s 
1
â€‹
 
 
â€‹
 
ğ‘¦
2
=
ğ‘’
ğ‘ 
2
ğ‘’
ğ‘ 
1
+
ğ‘’
ğ‘ 
2
y 
2
â€‹
 = 
e 
s 
1
â€‹
 
 +e 
s 
2
â€‹
 
 
e 
s 
2
â€‹
 
 
â€‹
 

Gradijent gubitka u odnosu na 
ğ‘ 
s:
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
=
ğ‘¦
1
âˆ’
1
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 =y 
1
â€‹
 âˆ’1
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
=
ğ‘¦
2
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 =y 
2
â€‹
 

Gradijent u odnosu na 
ğ‘¤
2
w 
2
â€‹
  i 
ğ‘
2
b 
2
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘¤
2
=
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
â‹…
â„
1
âˆ‚w 
2
â€‹
 
âˆ‚L
â€‹
 = 
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 â‹…h 
1
â€‹
 
âˆ‚
ğ¿
âˆ‚
ğ‘
2
=
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
âˆ‚b 
2
â€‹
 
âˆ‚L
â€‹
 = 
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 

Gradijent u odnosu na 
â„
1
h 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
â„
1
=
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
â‹…
ğ‘¤
2
âˆ‚h 
1
â€‹
 
âˆ‚L
â€‹
 = 
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 â‹…w 
2
â€‹
 

Gradijent u odnosu na 
ğ‘ 
1
s 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
=
(
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
+
âˆ‚
ğ¿
âˆ‚
â„
1
â‹…
ReLU
â€²
(
ğ‘ 
1
)
)
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 =( 
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 + 
âˆ‚h 
1
â€‹
 
âˆ‚L
â€‹
 â‹…ReLU 
â€²
 (s 
1
â€‹
 ))

Gradijent u odnosu na 
ğ‘¤
1
w 
1
â€‹
  i 
ğ‘
1
b 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘¤
1
=
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
â‹…
ğ‘¥
âˆ‚w 
1
â€‹
 
âˆ‚L
â€‹
 = 
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 â‹…x
âˆ‚
ğ¿
âˆ‚
ğ‘
1
=
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
âˆ‚b 
1
â€‹
 
âˆ‚L
â€‹
 = 
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 

SpecifiÄne vrijednosti
IzraÄunajmo 
ğ‘ 
1
s 
1
â€‹
 :
ğ‘ 
1
=
ğ‘¤
1
+
ğ‘
1
s 
1
â€‹
 =w 
1
â€‹
 +b 
1
â€‹
 

IzraÄunajmo 
â„
1
h 
1
â€‹
 :
â„
1
=
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
h 
1
â€‹
 =ReLU(w 
1
â€‹
 +b 
1
â€‹
 )

IzraÄunajmo 
ğ‘ 
2
s 
2
â€‹
 :
ğ‘ 
2
=
ğ‘¤
2
â‹…
ReLU
(
ğ‘¤
1
+
ğ‘
1
)
+
ğ‘
2
s 
2
â€‹
 =w 
2
â€‹
 â‹…ReLU(w 
1
â€‹
 +b 
1
â€‹
 )+b 
2
â€‹
 

IzraÄunajmo softmax izlaze 
ğ‘¦
1
y 
1
â€‹
  i 
ğ‘¦
2
y 
2
â€‹
 :
ğ‘¦
1
=
ğ‘’
ğ‘ 
1
ğ‘’
ğ‘ 
1
+
ğ‘’
ğ‘ 
2
y 
1
â€‹
 = 
e 
s 
1
â€‹
 
 +e 
s 
2
â€‹
 
 
e 
s 
1
â€‹
 
 
â€‹
 
ğ‘¦
2
=
ğ‘’
ğ‘ 
2
ğ‘’
ğ‘ 
1
+
ğ‘’
ğ‘ 
2
y 
2
â€‹
 = 
e 
s 
1
â€‹
 
 +e 
s 
2
â€‹
 
 
e 
s 
2
â€‹
 
 
â€‹
 

IzraÄunajmo gradijente gubitka:
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
=
ğ‘¦
1
âˆ’
1
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 =y 
1
â€‹
 âˆ’1
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
=
ğ‘¦
2
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 =y 
2
â€‹
 

IzraÄunajmo gradijente u odnosu na 
ğ‘¤
2
w 
2
â€‹
  i 
ğ‘
2
b 
2
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘¤
2
=
ğ‘¦
2
â‹…
â„
1
âˆ‚w 
2
â€‹
 
âˆ‚L
â€‹
 =y 
2
â€‹
 â‹…h 
1
â€‹
 
âˆ‚
ğ¿
âˆ‚
ğ‘
2
=
ğ‘¦
2
âˆ‚b 
2
â€‹
 
âˆ‚L
â€‹
 =y 
2
â€‹
 

IzraÄunajmo gradijent u odnosu na 
â„
1
h 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
â„
1
=
ğ‘¦
2
â‹…
ğ‘¤
2
âˆ‚h 
1
â€‹
 
âˆ‚L
â€‹
 =y 
2
â€‹
 â‹…w 
2
â€‹
 

IzraÄunajmo gradijent u odnosu na 
ğ‘ 
1
s 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
=
(
ğ‘¦
1
âˆ’
1
)
+
ğ‘¦
2
â‹…
ğ‘¤
2
â‹…
ReLU
â€²
(
ğ‘ 
1
)
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 =(y 
1
â€‹
 âˆ’1)+y 
2
â€‹
 â‹…w 
2
â€‹
 â‹…ReLU 
â€²
 (s 
1
â€‹
 )

{
1
akoÂ 
ğ‘ 
1
>
0
0
akoÂ 
ğ‘ 
1
â‰¤
0
{ 
1
0
â€‹
  
akoÂ s 
1
â€‹
 >0
akoÂ s 
1
â€‹
 â‰¤0
â€‹
 
IzraÄunajmo gradijente u odnosu na 
ğ‘¤
1
w 
1
â€‹
  i 
ğ‘
1
b 
1
â€‹
 :
âˆ‚
ğ¿
âˆ‚
ğ‘¤
1
=
(
(
ğ‘¦
1
âˆ’
1
)
+
ğ‘¦
2
â‹…
ğ‘¤
2
â‹…
ReLU
â€²
(
ğ‘ 
1
)
)
â‹…
ğ‘¥
âˆ‚w 
1
â€‹
 
âˆ‚L
â€‹
 =((y 
1
â€‹
 âˆ’1)+y 
2
â€‹
 â‹…w 
2
â€‹
 â‹…ReLU 
â€²
 (s 
1
â€‹
 ))â‹…x
âˆ‚
ğ¿
âˆ‚
ğ‘
1
=
(
ğ‘¦
1
âˆ’
1
)
+
ğ‘¦
2
â‹…
ğ‘¤
2
â‹…
ReLU
â€²
(
ğ‘ 
1
)
âˆ‚b 
1
â€‹
 
âˆ‚L
â€‹
 =(y 
1
â€‹
 âˆ’1)+y 
2
â€‹
 â‹…w 
2
â€‹
 â‹…ReLU 
â€²
 (s 
1
â€‹
 )

SpecifiÄne vrijednosti za 
ğ‘¥
=
1
x=1
Pretpostavimo da su:

ğ‘¤
1
=
1
,
ğ‘
1
=
0
,
ğ‘¤
2
=
1
,
ğ‘
2
=
0
w 
1
â€‹
 =1,b 
1
â€‹
 =0,w 
2
â€‹
 =1,b 
2
â€‹
 =0

Tada su:

ğ‘ 
1
=
1
+
0
=
1
s 
1
â€‹
 =1+0=1
â„
1
=
ReLU
(
1
)
=
1
h 
1
â€‹
 =ReLU(1)=1
ğ‘ 
2
=
1
â‹…
1
+
0
=
1
s 
2
â€‹
 =1â‹…1+0=1
ğ‘ 
=
[
1
,
1
]
s=[1,1]

Softmax izlazi:

ğ‘¦
1
=
ğ‘’
1
ğ‘’
1
+
ğ‘’
1
=
ğ‘’
2
ğ‘’
=
1
2
y 
1
â€‹
 = 
e 
1
 +e 
1
 
e 
1
 
â€‹
 = 
2e
e
â€‹
 = 
2
1
â€‹
 
ğ‘¦
2
=
ğ‘’
1
ğ‘’
1
+
ğ‘’
1
=
ğ‘’
2
ğ‘’
=
1
2
y 
2
â€‹
 = 
e 
1
 +e 
1
 
e 
1
 
â€‹
 = 
2e
e
â€‹
 = 
2
1
â€‹
 

Gradijenti gubitka:

âˆ‚
ğ¿
âˆ‚
ğ‘ 
1
=
1
2
âˆ’
1
=
âˆ’
1
2
âˆ‚s 
1
â€‹
 
âˆ‚L
â€‹
 = 
2
1
â€‹
 âˆ’1=âˆ’ 
2
1
â€‹
 
âˆ‚
ğ¿
âˆ‚
ğ‘ 
2
=
1
2
âˆ‚s 
2
â€‹
 
âˆ‚L
â€‹
 = 
2
1
â€‹
 

Gradijenti u odnosu na 
ğ‘¤
2
w 
2
â€‹
  i 
ğ‘
2
b 
2
â€‹
 :